2022-01-27 00:18:36,570 [loggers.py          ] [29 ] [INFO ]  	Start repetition 8 with MW_max_iter: 10000, sample_size_t: 50000, sample_size_s: 150000, subsample_size: 51221
2022-01-27 00:18:36,572 [loggers.py          ] [23 ] [INFO ]  		Prepare the target distribution
2022-01-27 00:18:39,914 [loggers.py          ] [23 ] [INFO ]  		Sample from the source distribution 150000 examples
2022-01-27 00:18:40,755 [loggers.py          ] [23 ] [INFO ]  		Start MW algorithm
2022-01-27 00:18:40,916 [loggers.py          ] [29 ] [INFO ]  			Iteration number 1 of MW algorithm with rep: 8, MW_max_iter: 10000, sample_size_t: 50000, sample_size_s: 150000, subsample_size: 51221
2022-01-27 00:18:41,068 [loggers.py          ] [23 ] [INFO ]  				Fit model on subsample
2022-01-27 00:18:43,909 [loggers.py          ] [23 ] [INFO ]  				Calculate loss on S
2022-01-27 00:18:44,210 [loggers.py          ] [23 ] [INFO ]  				SQ - query
2022-01-27 00:18:45,992 [loggers.py          ] [23 ] [INFO ]  				Loss S: 0.018973333333333335, Loss subsampling S: 0.01622381445110404, Loss T: 0.07214, Dist chisq: 16.54567208900538, Dist kl: 3.913947757065158, Dist tv: 0.9076513558204723
2022-01-27 00:18:46,006 [loggers.py          ] [29 ] [INFO ]  			Iteration number 2 of MW algorithm with rep: 8, MW_max_iter: 10000, sample_size_t: 50000, sample_size_s: 150000, subsample_size: 51221
2022-01-27 00:18:46,172 [loggers.py          ] [23 ] [INFO ]  				Fit model on subsample
2022-01-27 00:18:51,962 [loggers.py          ] [23 ] [INFO ]  				Calculate loss on S
2022-01-27 00:18:52,218 [loggers.py          ] [23 ] [INFO ]  				SQ - query
2022-01-27 00:18:53,658 [loggers.py          ] [23 ] [INFO ]  				Loss S: 0.014094263491446707, Loss subsampling S: 0.011440620058179262, Loss T: 0.02104, Dist chisq: 16.532862354414224, Dist kl: 3.9126884795905, Dist tv: 0.9075543597498803
2022-01-27 00:18:53,689 [loggers.py          ] [23 ] [INFO ]  	Finish repetition 8 of MW algorithm after 2 iterations in status succeeded: Loss S: 0.014094263491446707, Loss subsampling S: 0.011440620058179262, Loss T: 0.02104, chisq_dist: 16.532862354414224, kl_dist: 3.9126884795905, tv_dist: 0.9075543597498803 with MW_max_iter: 10000, sample_size_t: 50000, sample_size_s: 150000, subsample_size: 51221
